WARNING: Not monitoring node memory since `psutil` is not installed. Install this with `pip install psutil` (or ray[debug]) to enable debugging of memory-related crashes.
Memory address of ``policies``: 139650400981280
Memory address of ``policies``: 139650400981280
Memory address of ``policies``: 139650400981280
Memory address of ``self.policies``: 139650400981280
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[2m[36m(pid=30375)[0m   _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[2m[36m(pid=30375)[0m   _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[2m[36m(pid=30375)[0m   _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[2m[36m(pid=30375)[0m   _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[2m[36m(pid=30375)[0m   _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[2m[36m(pid=30375)[0m   np_resource = np.dtype([("resource", np.ubyte, 1)])
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
[2m[36m(pid=30375)[0m   return f(*args, **kwds)
[2m[36m(pid=30375)[0m 2019-09-23 12:03:16,661	WARNING compression.py:20 -- lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
[2m[36m(pid=30375)[0m 2019-09-23 12:03:17,324	INFO rollout_worker.py:319 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=30375)[0m 2019-09-23 12:03:17.325460: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
[2m[36m(pid=30375)[0m 2019-09-23 12:03:18,335	INFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:
[2m[36m(pid=30375)[0m 
[2m[36m(pid=30375)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=30375)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 3) dtype=int64>,
[2m[36m(pid=30375)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=30375)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 9) dtype=float32>,
[2m[36m(pid=30375)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=30375)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 100) dtype=float32>,
[2m[36m(pid=30375)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 100) dtype=float32>,
[2m[36m(pid=30375)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 3) dtype=int64>,
[2m[36m(pid=30375)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=30375)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=30375)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=30375)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=30375)[0m 
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[2m[36m(pid=30375)[0m   "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Has the reset occurred yet?
{   'batch_mode': 'truncate_episodes',
    'callbacks': {   'on_episode_end': None,
                     'on_episode_start': None,
                     'on_episode_step': None,
                     'on_postprocess_traj': None,
                     'on_sample_end': None,
                     'on_train_result': None},
    'clip_actions': True,
    'clip_param': 0.3,
    'clip_rewards': None,
    'collect_metrics_timeout': 180,
    'compress_observations': False,
    'custom_resources_per_worker': {},
    'entropy_coeff': 0.0,
    'entropy_coeff_schedule': None,
    'env': 'bee_world',
    'env_config': {},
    'evaluation_config': {},
    'evaluation_interval': None,
    'evaluation_num_episodes': 10,
    'gamma': 0.99,
    'grad_clip': None,
    'horizon': None,
    'ignore_worker_failures': False,
    'input': 'sampler',
    'input_evaluation': ['is', 'wis'],
    'kl_coeff': 0.2,
    'kl_target': 0.01,
    'lambda': 1.0,
    'local_tf_session_args': {   'inter_op_parallelism_threads': 8,
                                 'intra_op_parallelism_threads': 8},
    'log_level': 'INFO',
    'log_sys_usage': True,
    'lr': 5e-05,
    'lr_schedule': None,
    'metrics_smoothing_episodes': 100,
    'min_iter_time_s': 0,
    'model': {   'conv_activation': 'relu',
                 'conv_filters': None,
                 'custom_model': None,
                 'custom_options': {},
                 'custom_preprocessor': None,
                 'dim': 84,
                 'fcnet_activation': 'tanh',
                 'fcnet_hiddens': [256, 256],
                 'framestack': True,
                 'free_log_std': False,
                 'grayscale': False,
                 'lstm_cell_size': 256,
                 'lstm_use_prev_action_reward': False,
                 'max_seq_len': 20,
                 'no_final_linear': False,
                 'state_shape': None,
                 'use_lstm': False,
                 'vf_share_layers': True,
                 'zero_mean': True},
    'monitor': False,
    'multiagent': {   'policies': {},
                      'policies_to_train': None,
                      'policy_mapping_fn': <function policy_mapping_fn at 0x7f03047e3ea0>},
    'num_cpus_for_driver': 1,
    'num_cpus_per_worker': 1,
    'num_envs_per_worker': 1,
    'num_gpus': 0,
    'num_gpus_per_worker': 0,
    'num_sgd_iter': 30,
    'num_workers': 1,
    'observation_filter': 'NoFilter',
    'optimizer': {},
    'output': None,
    'output_compress_columns': ['obs', 'new_obs'],
    'output_max_file_size': 67108864,
    'postprocess_inputs': False,
    'preprocessor_pref': 'deepmind',
    'remote_env_batch_wait_ms': 0,
    'remote_worker_envs': False,
    'sample_async': False,
    'sample_batch_size': 200,
    'seed': None,
    'sgd_minibatch_size': 128,
    'shuffle_buffer_size': 0,
    'shuffle_sequences': True,
    'simple_optimizer': False,
    'soft_horizon': False,
    'synchronize_filters': True,
    'tf_session_args': {   'allow_soft_placement': True,
                           'device_count': {'CPU': 1},
                           'gpu_options': {'allow_growth': True},
                           'inter_op_parallelism_threads': 2,
                           'intra_op_parallelism_threads': 2,
                           'log_device_placement': False},
    'timesteps_per_iteration': 0,
    'train_batch_size': 4000,
    'use_gae': True,
    'vf_clip_param': 10.0,
    'vf_loss_coeff': 1.0,
    'vf_share_layers': False}
ppo_trainer config: None
trainer_policies memory address: 139650398329304
{   'batch_mode': 'truncate_episodes',
    'callbacks': {   'on_episode_end': None,
                     'on_episode_start': None,
                     'on_episode_step': None,
                     'on_postprocess_traj': None,
                     'on_sample_end': None,
                     'on_train_result': None},
    'clip_actions': True,
    'clip_param': 0.3,
    'clip_rewards': None,
    'collect_metrics_timeout': 180,
    'compress_observations': False,
    'custom_resources_per_worker': {},
    'entropy_coeff': 0.0,
    'entropy_coeff_schedule': None,
    'env': 'bee_world',
    'env_config': {},
    'evaluation_config': {},
    'evaluation_interval': None,
    'evaluation_num_episodes': 10,
    'gamma': 0.99,
    'grad_clip': None,
    'horizon': None,
    'ignore_worker_failures': False,
    'input': 'sampler',
    'input_evaluation': ['is', 'wis'],
    'kl_coeff': 0.2,
    'kl_target': 0.01,
    'lambda': 1.0,
    'local_tf_session_args': {   'inter_op_parallelism_threads': 8,
                                 'intra_op_parallelism_threads': 8},
    'log_level': 'INFO',
    'log_sys_usage': True,
    'lr': 5e-05,
    'lr_schedule': None,
    'metrics_smoothing_episodes': 100,
    'min_iter_time_s': 0,
    'model': {   'conv_activation': 'relu',
                 'conv_filters': None,
                 'custom_model': None,
                 'custom_options': {},
                 'custom_preprocessor': None,
                 'dim': 84,
                 'fcnet_activation': 'tanh',
                 'fcnet_hiddens': [256, 256],
                 'framestack': True,
                 'free_log_std': False,
                 'grayscale': False,
                 'lstm_cell_size': 256,
                 'lstm_use_prev_action_reward': False,
                 'max_seq_len': 20,
                 'no_final_linear': False,
                 'state_shape': None,
                 'use_lstm': False,
                 'vf_share_layers': True,
                 'zero_mean': True},
    'monitor': False,
    'multiagent': {   'policies': {'0': (None, None, None, None)},
                      'policies_to_train': None,
                      'policy_mapping_fn': <function policy_mapping_fn at 0x7f03047e3ea0>},
    'num_cpus_for_driver': 1,
    'num_cpus_per_worker': 1,
    'num_envs_per_worker': 1,
    'num_gpus': 0,
    'num_gpus_per_worker': 0,
    'num_sgd_iter': 30,
    'num_workers': 1,
    'observation_filter': 'NoFilter',
    'optimizer': {},
    'output': None,
    'output_compress_columns': ['obs', 'new_obs'],
    'output_max_file_size': 67108864,
    'postprocess_inputs': False,
    'preprocessor_pref': 'deepmind',
    'remote_env_batch_wait_ms': 0,
    'remote_worker_envs': False,
    'sample_async': False,
    'sample_batch_size': 200,
    'seed': None,
    'sgd_minibatch_size': 128,
    'shuffle_buffer_size': 0,
    'shuffle_sequences': True,
    'simple_optimizer': False,
    'soft_horizon': False,
    'synchronize_filters': True,
    'tf_session_args': {   'allow_soft_placement': True,
                           'device_count': {'CPU': 1},
                           'gpu_options': {'allow_growth': True},
                           'inter_op_parallelism_threads': 2,
                           'intra_op_parallelism_threads': 2,
                           'log_device_placement': False},
    'timesteps_per_iteration': 0,
    'train_batch_size': 4000,
    'use_gae': True,
    'vf_clip_param': 10.0,
    'vf_loss_coeff': 1.0,
    'vf_share_layers': False}
ppo_trainer config: None
== Iteration 0 ==
-- PPO --
[2m[36m(pid=30375)[0m ========RESETTING_ENVIRONMENT========
[2m[36m(pid=30375)[0m Memory address of ``self.policies``: 139867492519440
[2m[36m(pid=30375)[0m env.reset(): self.policies: {}
[2m[36m(pid=30375)[0m Memory address of ``self.policies``: 139867492519440
[2m[36m(pid=30375)[0m rllib/evaluation/episode/py: DEBUG.
[2m[36m(pid=30375)[0m 2019-09-23 12:03:21,899	INFO rollout_worker.py:451 -- Generating sample batch of size 200
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
[2m[36m(pid=30375)[0m   out=out, **kwargs)
[2m[36m(pid=30375)[0m /homes/3/whitaker.213/anaconda3/envs/rllib_editable/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
[2m[36m(pid=30375)[0m   ret = ret.dtype.type(ret / rcount)
[2m[36m(pid=30375)[0m 2019-09-23 12:03:21,935	INFO sampler.py:304 -- Raw obs from env: { 0: { 0: ( ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (1, 0), (0, 0), (0, 1)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (1, 0), (1, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 1), (0, 1)),
[2m[36m(pid=30375)[0m             ((1, 0), (0, 0), (0, 0), (0, 0), (0, 0))),
[2m[36m(pid=30375)[0m        1: ( ((0, 0), (0, 0), (0, 0), (0, 0), (1, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (1, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (1, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0))),
[2m[36m(pid=30375)[0m        2: ( ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (1, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (1, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0))),
[2m[36m(pid=30375)[0m        3: ( ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (1, 0), (0, 0), (0, 1), (0, 1)),
[2m[36m(pid=30375)[0m             ((0, 0), (1, 0), (1, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 1), (0, 1), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0))),
[2m[36m(pid=30375)[0m        4: ( ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (1, 0), (0, 0), (0, 1)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (1, 0), (1, 0), (0, 0)),
[2m[36m(pid=30375)[0m             ((0, 0), (0, 0), (0, 0), (0, 1), (0, 1)))}}
[2m[36m(pid=30375)[0m 2019-09-23 12:03:21,935	INFO sampler.py:305 -- Info return from env: {0: {0: {}, 1: {}, 2: {}, 3: {}, 4: {}}}
